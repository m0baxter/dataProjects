{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet hate speech classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy  as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score, matthews_corrcoef\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, BatchNormalization, Bidirectional\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv( \"train_E6oV3lV.csv\" )\n",
    "test = pd.read_csv( \"test_tweets_anuFYb8.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      0   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      0                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      0             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uniqueWords( data ):\n",
    "    \"\"\"Return a set of the words in data.\"\"\"\n",
    "\n",
    "    words = set([])\n",
    "\n",
    "    for tweet in data:\n",
    "        for w in tweet.split():\n",
    "            words.add(w)\n",
    "\n",
    "    return words\n",
    "\n",
    "def uniqueChars( data ):\n",
    "    \"\"\"Return a set of the characters in data.\"\"\"\n",
    "\n",
    "    chars = set([])\n",
    "\n",
    "    for tweet in data:\n",
    "        for c in tweet:\n",
    "            chars.add(c)\n",
    "\n",
    "    return chars\n",
    "\n",
    "def tweetLens( data ):\n",
    "    \"\"\"Find the lengths of all the tweets in the data set.\"\"\"\n",
    "\n",
    "    lens = []\n",
    "\n",
    "    for t in data:\n",
    "        lens.append( len(t) )\n",
    "\n",
    "    return lens\n",
    "\n",
    "def genDicts( chars ):\n",
    "    \"\"\"Generate dictionaries used to encode/decode the tweets.\"\"\"\n",
    "\n",
    "    c2i = { c : i + 1 for i, c in enumerate( sorted(chars) ) }\n",
    "    i2c = { i + 1 : c for i, c in enumerate( sorted(chars) ) }\n",
    "\n",
    "    return c2i, i2c\n",
    "\n",
    "def encode( tweet, c2i ):\n",
    "    \"\"\"Encode the tweet into a list of integers.\"\"\"\n",
    "\n",
    "    code = []\n",
    "\n",
    "    for c in tweet:\n",
    "        code.append( c2i[c] )\n",
    "\n",
    "    return code\n",
    "\n",
    "def decode( code, i2c ):\n",
    "    \"\"\"Decode a list of integers into a tweet.\"\"\"\n",
    "\n",
    "    sentence = []\n",
    "\n",
    "    for i in code:\n",
    "        sentence.append( i2c[i] )\n",
    "\n",
    "    return \"\".join(sentence)\n",
    "\n",
    "def padList( l, p, n ):\n",
    "    \"\"\"Add padding p to the list l such that its length becomes n.\"\"\"\n",
    "\n",
    "    while ( len(l) < n ):\n",
    "        l.append(p)\n",
    "\n",
    "    return l\n",
    "\n",
    "def genData( data, c2i ):\n",
    "    \"\"\"Encode/pad the data set.\"\"\"\n",
    "\n",
    "    X = []\n",
    "\n",
    "    for t in data.tweet:\n",
    "        code = encode( t, c2i )\n",
    "        code = padList( code, 0, 300 )\n",
    "\n",
    "        X.append(code)\n",
    "\n",
    "    return np.array(X), np.array( data[\"label\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enumerate the unique characters present in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = uniqueWords( test.tweet )\n",
    "w2 = uniqueWords( train.tweet )\n",
    "\n",
    "c1 = uniqueChars( test.tweet )\n",
    "c2 = uniqueChars( train.tweet )\n",
    "\n",
    "l1 = tweetLens( test.tweet )\n",
    "l2 = tweetLens( train.tweet )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set.union(c1,c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2i, i2c = genDicts( chars )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = genData( train, c2i )\n",
    "\n",
    "trainX, valX, trainY, valY = train_test_split( X, y, test_size = 0.1, random_state = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genModel( embed = 32, nl = 1, nh = 32, do = 0.5, rdo = 0.5 ):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add( Embedding( input_dim = 167, output_dim = embed, input_length = 300, mask_zero = True ) )\n",
    "    model.add( BatchNormalization() )\n",
    "\n",
    "    for _ in range(nl - 1):\n",
    "        model.add( Bidirectional( LSTM( nh, dropout = do, recurrent_dropout = rdo, return_sequences = True ) ) )\n",
    "\n",
    "    model.add( Bidirectional( LSTM( nh, dropout = do, recurrent_dropout = rdo ) ) )\n",
    "    model.add( BatchNormalization() )\n",
    "    model.add( Dense(1, activation = \"sigmoid\") )\n",
    "\n",
    "    model.compile( loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = ['acc'] )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 64)           10688     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 300, 64)           256       \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 300, 128)          66048     \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 300, 128)          98816     \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 275,265\n",
      "Trainable params: 274,881\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Train on 28765 samples, validate on 3197 samples\n",
      "Epoch 1/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.5858 - acc: 0.7370\n",
      "Epoch 00001: val_loss improved from inf to 0.39823, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 117s 4ms/step - loss: 0.5854 - acc: 0.7374 - val_loss: 0.3982 - val_acc: 0.9271\n",
      "Epoch 2/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.3323 - acc: 0.9250\n",
      "Epoch 00002: val_loss improved from 0.39823 to 0.23533, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 113s 4ms/step - loss: 0.3321 - acc: 0.9250 - val_loss: 0.2353 - val_acc: 0.9271\n",
      "Epoch 3/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.2420 - acc: 0.9300\n",
      "Epoch 00003: val_loss improved from 0.23533 to 0.20621, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 121s 4ms/step - loss: 0.2422 - acc: 0.9299 - val_loss: 0.2062 - val_acc: 0.9356\n",
      "Epoch 4/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.2191 - acc: 0.9311\n",
      "Epoch 00004: val_loss improved from 0.20621 to 0.19132, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 115s 4ms/step - loss: 0.2188 - acc: 0.9312 - val_loss: 0.1913 - val_acc: 0.9378\n",
      "Epoch 5/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9342\n",
      "Epoch 00005: val_loss did not improve\n",
      "28765/28765 [==============================] - 122s 4ms/step - loss: 0.2006 - acc: 0.9342 - val_loss: 0.1922 - val_acc: 0.9381\n",
      "Epoch 6/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1896 - acc: 0.9386\n",
      "Epoch 00006: val_loss improved from 0.19132 to 0.16888, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 120s 4ms/step - loss: 0.1898 - acc: 0.9385 - val_loss: 0.1689 - val_acc: 0.9446\n",
      "Epoch 7/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1757 - acc: 0.9411\n",
      "Epoch 00007: val_loss improved from 0.16888 to 0.15768, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 118s 4ms/step - loss: 0.1756 - acc: 0.9410 - val_loss: 0.1577 - val_acc: 0.9462\n",
      "Epoch 8/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1622 - acc: 0.9435\n",
      "Epoch 00008: val_loss did not improve\n",
      "28765/28765 [==============================] - 115s 4ms/step - loss: 0.1620 - acc: 0.9436 - val_loss: 0.1666 - val_acc: 0.9484\n",
      "Epoch 9/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1501 - acc: 0.9482\n",
      "Epoch 00009: val_loss improved from 0.15768 to 0.13408, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 115s 4ms/step - loss: 0.1503 - acc: 0.9482 - val_loss: 0.1341 - val_acc: 0.9581\n",
      "Epoch 10/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1467 - acc: 0.9500\n",
      "Epoch 00010: val_loss improved from 0.13408 to 0.12980, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.1465 - acc: 0.9500 - val_loss: 0.1298 - val_acc: 0.9587\n",
      "Epoch 11/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9481\n",
      "Epoch 00011: val_loss did not improve\n",
      "28765/28765 [==============================] - 116s 4ms/step - loss: 0.1491 - acc: 0.9482 - val_loss: 0.1359 - val_acc: 0.9559\n",
      "Epoch 12/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1389 - acc: 0.9519\n",
      "Epoch 00012: val_loss did not improve\n",
      "28765/28765 [==============================] - 115s 4ms/step - loss: 0.1388 - acc: 0.9519 - val_loss: 0.1339 - val_acc: 0.9584\n",
      "Epoch 13/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9547\n",
      "Epoch 00013: val_loss improved from 0.12980 to 0.12170, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.1291 - acc: 0.9547 - val_loss: 0.1217 - val_acc: 0.9615\n",
      "Epoch 14/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1235 - acc: 0.9573\n",
      "Epoch 00014: val_loss improved from 0.12170 to 0.11548, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.1236 - acc: 0.9574 - val_loss: 0.1155 - val_acc: 0.9631\n",
      "Epoch 15/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1183 - acc: 0.9592\n",
      "Epoch 00015: val_loss improved from 0.11548 to 0.11369, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.1183 - acc: 0.9592 - val_loss: 0.1137 - val_acc: 0.9637\n",
      "Epoch 16/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9593\n",
      "Epoch 00016: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.1175 - acc: 0.9592 - val_loss: 0.1147 - val_acc: 0.9628\n",
      "Epoch 17/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9611\n",
      "Epoch 00017: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.1127 - acc: 0.9612 - val_loss: 0.1176 - val_acc: 0.9606\n",
      "Epoch 18/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9604\n",
      "Epoch 00018: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.1139 - acc: 0.9604 - val_loss: 0.1144 - val_acc: 0.9615\n",
      "Epoch 19/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9619\n",
      "Epoch 00019: val_loss improved from 0.11369 to 0.11138, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.1120 - acc: 0.9619 - val_loss: 0.1114 - val_acc: 0.9643\n",
      "Epoch 20/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9621\n",
      "Epoch 00020: val_loss improved from 0.11138 to 0.10948, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.1086 - acc: 0.9622 - val_loss: 0.1095 - val_acc: 0.9631\n",
      "Epoch 21/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1051 - acc: 0.9648\n",
      "Epoch 00021: val_loss improved from 0.10948 to 0.10769, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.1053 - acc: 0.9647 - val_loss: 0.1077 - val_acc: 0.9625\n",
      "Epoch 22/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1060 - acc: 0.9643\n",
      "Epoch 00022: val_loss improved from 0.10769 to 0.10677, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.1059 - acc: 0.9643 - val_loss: 0.1068 - val_acc: 0.9634\n",
      "Epoch 23/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9652\n",
      "Epoch 00023: val_loss improved from 0.10677 to 0.10311, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.1020 - acc: 0.9653 - val_loss: 0.1031 - val_acc: 0.9656\n",
      "Epoch 24/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.1027 - acc: 0.9659\n",
      "Epoch 00024: val_loss did not improve\n",
      "28765/28765 [==============================] - 120s 4ms/step - loss: 0.1026 - acc: 0.9660 - val_loss: 0.1032 - val_acc: 0.9665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0988 - acc: 0.9666\n",
      "Epoch 00025: val_loss did not improve\n",
      "28765/28765 [==============================] - 121s 4ms/step - loss: 0.0990 - acc: 0.9665 - val_loss: 0.1050 - val_acc: 0.9650\n",
      "Epoch 26/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9654\n",
      "Epoch 00026: val_loss did not improve\n",
      "28765/28765 [==============================] - 114s 4ms/step - loss: 0.0994 - acc: 0.9654 - val_loss: 0.1033 - val_acc: 0.9650\n",
      "Epoch 27/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0999 - acc: 0.9658\n",
      "Epoch 00027: val_loss improved from 0.10311 to 0.10232, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0997 - acc: 0.9658 - val_loss: 0.1023 - val_acc: 0.9647\n",
      "Epoch 28/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9685\n",
      "Epoch 00028: val_loss improved from 0.10232 to 0.10044, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0951 - acc: 0.9685 - val_loss: 0.1004 - val_acc: 0.9678\n",
      "Epoch 29/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0966 - acc: 0.9677\n",
      "Epoch 00029: val_loss improved from 0.10044 to 0.09717, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0967 - acc: 0.9676 - val_loss: 0.0972 - val_acc: 0.9684\n",
      "Epoch 30/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9675\n",
      "Epoch 00030: val_loss improved from 0.09717 to 0.09700, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0950 - acc: 0.9675 - val_loss: 0.0970 - val_acc: 0.9684\n",
      "Epoch 31/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9693\n",
      "Epoch 00031: val_loss did not improve\n",
      "28765/28765 [==============================] - 118s 4ms/step - loss: 0.0915 - acc: 0.9691 - val_loss: 0.0976 - val_acc: 0.9672\n",
      "Epoch 32/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9697\n",
      "Epoch 00032: val_loss did not improve\n",
      "28765/28765 [==============================] - 118s 4ms/step - loss: 0.0917 - acc: 0.9698 - val_loss: 0.0970 - val_acc: 0.9675\n",
      "Epoch 33/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0920 - acc: 0.9694\n",
      "Epoch 00033: val_loss did not improve\n",
      "28765/28765 [==============================] - 114s 4ms/step - loss: 0.0919 - acc: 0.9695 - val_loss: 0.0973 - val_acc: 0.9700\n",
      "Epoch 34/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0892 - acc: 0.9705\n",
      "Epoch 00034: val_loss improved from 0.09700 to 0.09675, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0892 - acc: 0.9705 - val_loss: 0.0967 - val_acc: 0.9687\n",
      "Epoch 35/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0896 - acc: 0.9692\n",
      "Epoch 00035: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0895 - acc: 0.9692 - val_loss: 0.0970 - val_acc: 0.9684\n",
      "Epoch 36/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9699\n",
      "Epoch 00036: val_loss improved from 0.09675 to 0.09651, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 113s 4ms/step - loss: 0.0881 - acc: 0.9700 - val_loss: 0.0965 - val_acc: 0.9675\n",
      "Epoch 37/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9716\n",
      "Epoch 00037: val_loss improved from 0.09651 to 0.09212, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 113s 4ms/step - loss: 0.0853 - acc: 0.9716 - val_loss: 0.0921 - val_acc: 0.9703\n",
      "Epoch 38/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9709\n",
      "Epoch 00038: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0851 - acc: 0.9709 - val_loss: 0.0927 - val_acc: 0.9690\n",
      "Epoch 39/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0842 - acc: 0.9712\n",
      "Epoch 00039: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0840 - acc: 0.9712 - val_loss: 0.0973 - val_acc: 0.9681\n",
      "Epoch 40/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0855 - acc: 0.9719\n",
      "Epoch 00040: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0854 - acc: 0.9720 - val_loss: 0.0979 - val_acc: 0.9675\n",
      "Epoch 41/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0822 - acc: 0.9726\n",
      "Epoch 00041: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0821 - acc: 0.9725 - val_loss: 0.0929 - val_acc: 0.9712\n",
      "Epoch 42/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0808 - acc: 0.9729\n",
      "Epoch 00042: val_loss improved from 0.09212 to 0.09212, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0807 - acc: 0.9729 - val_loss: 0.0921 - val_acc: 0.9697\n",
      "Epoch 43/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0810 - acc: 0.9725\n",
      "Epoch 00043: val_loss improved from 0.09212 to 0.09158, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0809 - acc: 0.9725 - val_loss: 0.0916 - val_acc: 0.9712\n",
      "Epoch 44/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0799 - acc: 0.9734\n",
      "Epoch 00044: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0798 - acc: 0.9734 - val_loss: 0.0963 - val_acc: 0.9706\n",
      "Epoch 45/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9730\n",
      "Epoch 00045: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0818 - acc: 0.9730 - val_loss: 0.0952 - val_acc: 0.9690\n",
      "Epoch 46/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0784 - acc: 0.9738\n",
      "Epoch 00046: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0787 - acc: 0.9738 - val_loss: 0.0916 - val_acc: 0.9731\n",
      "Epoch 47/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0769 - acc: 0.9748\n",
      "Epoch 00047: val_loss improved from 0.09158 to 0.08829, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0768 - acc: 0.9748 - val_loss: 0.0883 - val_acc: 0.9712\n",
      "Epoch 48/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0759 - acc: 0.9750\n",
      "Epoch 00048: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0760 - acc: 0.9750 - val_loss: 0.0907 - val_acc: 0.9687\n",
      "Epoch 49/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0742 - acc: 0.9754\n",
      "Epoch 00049: val_loss improved from 0.08829 to 0.08824, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0741 - acc: 0.9754 - val_loss: 0.0882 - val_acc: 0.9734\n",
      "Epoch 50/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0737 - acc: 0.9751\n",
      "Epoch 00050: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0735 - acc: 0.9752 - val_loss: 0.0910 - val_acc: 0.9712\n",
      "Epoch 51/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0731 - acc: 0.9752\n",
      "Epoch 00051: val_loss improved from 0.08824 to 0.08570, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0732 - acc: 0.9752 - val_loss: 0.0857 - val_acc: 0.9737\n",
      "Epoch 52/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9745\n",
      "Epoch 00052: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0732 - acc: 0.9746 - val_loss: 0.0861 - val_acc: 0.9750\n",
      "Epoch 53/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0732 - acc: 0.9747\n",
      "Epoch 00053: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0732 - acc: 0.9747 - val_loss: 0.0860 - val_acc: 0.9728\n",
      "Epoch 54/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0726 - acc: 0.9756\n",
      "Epoch 00054: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0725 - acc: 0.9757 - val_loss: 0.0879 - val_acc: 0.9725\n",
      "Epoch 55/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0719 - acc: 0.9756\n",
      "Epoch 00055: val_loss improved from 0.08570 to 0.08413, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0720 - acc: 0.9756 - val_loss: 0.0841 - val_acc: 0.9709\n",
      "Epoch 56/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0696 - acc: 0.9758\n",
      "Epoch 00056: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0695 - acc: 0.9758 - val_loss: 0.0847 - val_acc: 0.9737\n",
      "Epoch 57/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0691 - acc: 0.9761\n",
      "Epoch 00057: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0691 - acc: 0.9761 - val_loss: 0.0894 - val_acc: 0.9706\n",
      "Epoch 58/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9767\n",
      "Epoch 00058: val_loss improved from 0.08413 to 0.08096, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0692 - acc: 0.9767 - val_loss: 0.0810 - val_acc: 0.9740\n",
      "Epoch 59/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9776\n",
      "Epoch 00059: val_loss improved from 0.08096 to 0.07979, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0689 - acc: 0.9776 - val_loss: 0.0798 - val_acc: 0.9744\n",
      "Epoch 60/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0658 - acc: 0.9772\n",
      "Epoch 00060: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0663 - acc: 0.9771 - val_loss: 0.0814 - val_acc: 0.9737\n",
      "Epoch 61/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0659 - acc: 0.9775\n",
      "Epoch 00061: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0658 - acc: 0.9775 - val_loss: 0.0829 - val_acc: 0.9734\n",
      "Epoch 62/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9780\n",
      "Epoch 00062: val_loss improved from 0.07979 to 0.07968, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0649 - acc: 0.9781 - val_loss: 0.0797 - val_acc: 0.9740\n",
      "Epoch 63/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0650 - acc: 0.9776\n",
      "Epoch 00063: val_loss improved from 0.07968 to 0.07769, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0650 - acc: 0.9776 - val_loss: 0.0777 - val_acc: 0.9753\n",
      "Epoch 64/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0626 - acc: 0.9787\n",
      "Epoch 00064: val_loss did not improve\n",
      "28765/28765 [==============================] - 114s 4ms/step - loss: 0.0626 - acc: 0.9787 - val_loss: 0.0791 - val_acc: 0.9734\n",
      "Epoch 65/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0624 - acc: 0.9784\n",
      "Epoch 00065: val_loss did not improve\n",
      "28765/28765 [==============================] - 114s 4ms/step - loss: 0.0622 - acc: 0.9785 - val_loss: 0.0780 - val_acc: 0.9740\n",
      "Epoch 66/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0643 - acc: 0.9784\n",
      "Epoch 00066: val_loss improved from 0.07769 to 0.07620, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 121s 4ms/step - loss: 0.0642 - acc: 0.9784 - val_loss: 0.0762 - val_acc: 0.9762\n",
      "Epoch 67/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0623 - acc: 0.9783\n",
      "Epoch 00067: val_loss improved from 0.07620 to 0.07449, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 115s 4ms/step - loss: 0.0622 - acc: 0.9783 - val_loss: 0.0745 - val_acc: 0.9753\n",
      "Epoch 68/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9783\n",
      "Epoch 00068: val_loss did not improve\n",
      "28765/28765 [==============================] - 117s 4ms/step - loss: 0.0627 - acc: 0.9783 - val_loss: 0.0754 - val_acc: 0.9762\n",
      "Epoch 69/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9789\n",
      "Epoch 00069: val_loss did not improve\n",
      "28765/28765 [==============================] - 114s 4ms/step - loss: 0.0611 - acc: 0.9789 - val_loss: 0.0781 - val_acc: 0.9750\n",
      "Epoch 70/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0622 - acc: 0.9793\n",
      "Epoch 00070: val_loss improved from 0.07449 to 0.07315, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 116s 4ms/step - loss: 0.0621 - acc: 0.9793 - val_loss: 0.0732 - val_acc: 0.9778\n",
      "Epoch 71/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0612 - acc: 0.9792\n",
      "Epoch 00071: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0611 - acc: 0.9792 - val_loss: 0.0750 - val_acc: 0.9759\n",
      "Epoch 72/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0586 - acc: 0.9790\n",
      "Epoch 00072: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0586 - acc: 0.9790 - val_loss: 0.0764 - val_acc: 0.9762\n",
      "Epoch 73/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0579 - acc: 0.9794\n",
      "Epoch 00073: val_loss did not improve\n",
      "28765/28765 [==============================] - 115s 4ms/step - loss: 0.0579 - acc: 0.9794 - val_loss: 0.0759 - val_acc: 0.9775\n",
      "Epoch 74/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9795\n",
      "Epoch 00074: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0573 - acc: 0.9795 - val_loss: 0.0760 - val_acc: 0.9765\n",
      "Epoch 75/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0564 - acc: 0.9810\n",
      "Epoch 00075: val_loss did not improve\n",
      "28765/28765 [==============================] - 118s 4ms/step - loss: 0.0564 - acc: 0.9810 - val_loss: 0.0757 - val_acc: 0.9765\n",
      "Epoch 76/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0560 - acc: 0.9799\n",
      "Epoch 00076: val_loss did not improve\n",
      "28765/28765 [==============================] - 113s 4ms/step - loss: 0.0560 - acc: 0.9799 - val_loss: 0.0737 - val_acc: 0.9778\n",
      "Epoch 77/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0574 - acc: 0.9796\n",
      "Epoch 00077: val_loss did not improve\n",
      "28765/28765 [==============================] - 115s 4ms/step - loss: 0.0575 - acc: 0.9796 - val_loss: 0.0803 - val_acc: 0.9753\n",
      "Epoch 78/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0568 - acc: 0.9805\n",
      "Epoch 00078: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0567 - acc: 0.9805 - val_loss: 0.0748 - val_acc: 0.9759\n",
      "Epoch 79/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0559 - acc: 0.9800\n",
      "Epoch 00079: val_loss improved from 0.07315 to 0.07263, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 115s 4ms/step - loss: 0.0558 - acc: 0.9800 - val_loss: 0.0726 - val_acc: 0.9762\n",
      "Epoch 80/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0542 - acc: 0.9810\n",
      "Epoch 00080: val_loss improved from 0.07263 to 0.07029, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0543 - acc: 0.9809 - val_loss: 0.0703 - val_acc: 0.9775\n",
      "Epoch 81/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0546 - acc: 0.9812\n",
      "Epoch 00081: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0546 - acc: 0.9812 - val_loss: 0.0719 - val_acc: 0.9769\n",
      "Epoch 82/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0523 - acc: 0.9809\n",
      "Epoch 00082: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0525 - acc: 0.9809 - val_loss: 0.0732 - val_acc: 0.9769\n",
      "Epoch 83/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0540 - acc: 0.9817\n",
      "Epoch 00083: val_loss improved from 0.07029 to 0.07008, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0540 - acc: 0.9816 - val_loss: 0.0701 - val_acc: 0.9750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0538 - acc: 0.9807\n",
      "Epoch 00084: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0537 - acc: 0.9807 - val_loss: 0.0712 - val_acc: 0.9772\n",
      "Epoch 85/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0534 - acc: 0.9798\n",
      "Epoch 00085: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0534 - acc: 0.9798 - val_loss: 0.0731 - val_acc: 0.9765\n",
      "Epoch 86/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0519 - acc: 0.9814\n",
      "Epoch 00086: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0520 - acc: 0.9814 - val_loss: 0.0716 - val_acc: 0.9759\n",
      "Epoch 87/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0510 - acc: 0.9832\n",
      "Epoch 00087: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0512 - acc: 0.9831 - val_loss: 0.0734 - val_acc: 0.9762\n",
      "Epoch 88/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0518 - acc: 0.9811\n",
      "Epoch 00088: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0519 - acc: 0.9811 - val_loss: 0.0745 - val_acc: 0.9769\n",
      "Epoch 89/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0497 - acc: 0.9818\n",
      "Epoch 00089: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0497 - acc: 0.9819 - val_loss: 0.0761 - val_acc: 0.9781\n",
      "Epoch 90/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0485 - acc: 0.9826\n",
      "Epoch 00090: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0483 - acc: 0.9826 - val_loss: 0.0711 - val_acc: 0.9778\n",
      "Epoch 91/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0495 - acc: 0.9823\n",
      "Epoch 00091: val_loss improved from 0.07008 to 0.06990, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0496 - acc: 0.9822 - val_loss: 0.0699 - val_acc: 0.9781\n",
      "Epoch 92/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0487 - acc: 0.9824\n",
      "Epoch 00092: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0487 - acc: 0.9823 - val_loss: 0.0728 - val_acc: 0.9769\n",
      "Epoch 93/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0483 - acc: 0.9824\n",
      "Epoch 00093: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0483 - acc: 0.9824 - val_loss: 0.0710 - val_acc: 0.9781\n",
      "Epoch 94/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0466 - acc: 0.9828\n",
      "Epoch 00094: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0467 - acc: 0.9828 - val_loss: 0.0707 - val_acc: 0.9784\n",
      "Epoch 95/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0474 - acc: 0.9825\n",
      "Epoch 00095: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0475 - acc: 0.9824 - val_loss: 0.0705 - val_acc: 0.9797\n",
      "Epoch 96/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0478 - acc: 0.9821\n",
      "Epoch 00096: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0477 - acc: 0.9822 - val_loss: 0.0712 - val_acc: 0.9787\n",
      "Epoch 97/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0465 - acc: 0.9830\n",
      "Epoch 00097: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0465 - acc: 0.9830 - val_loss: 0.0721 - val_acc: 0.9784\n",
      "Epoch 98/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0490 - acc: 0.9828\n",
      "Epoch 00098: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0493 - acc: 0.9827 - val_loss: 0.0700 - val_acc: 0.9784\n",
      "Epoch 99/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0496 - acc: 0.9816\n",
      "Epoch 00099: val_loss improved from 0.06990 to 0.06952, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0495 - acc: 0.9816 - val_loss: 0.0695 - val_acc: 0.9797\n",
      "Epoch 100/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9830\n",
      "Epoch 00100: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0470 - acc: 0.9829 - val_loss: 0.0698 - val_acc: 0.9794\n",
      "Epoch 101/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0451 - acc: 0.9831\n",
      "Epoch 00101: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0451 - acc: 0.9830 - val_loss: 0.0723 - val_acc: 0.9790\n",
      "Epoch 102/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0471 - acc: 0.9831\n",
      "Epoch 00102: val_loss improved from 0.06952 to 0.06910, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0471 - acc: 0.9831 - val_loss: 0.0691 - val_acc: 0.9794\n",
      "Epoch 103/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0445 - acc: 0.9846\n",
      "Epoch 00103: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0445 - acc: 0.9846 - val_loss: 0.0693 - val_acc: 0.9803\n",
      "Epoch 104/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0449 - acc: 0.9838\n",
      "Epoch 00104: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0453 - acc: 0.9838 - val_loss: 0.0695 - val_acc: 0.9784\n",
      "Epoch 105/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0431 - acc: 0.9842\n",
      "Epoch 00105: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0431 - acc: 0.9842 - val_loss: 0.0695 - val_acc: 0.9790\n",
      "Epoch 106/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0417 - acc: 0.9849\n",
      "Epoch 00106: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0416 - acc: 0.9849 - val_loss: 0.0706 - val_acc: 0.9803\n",
      "Epoch 107/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0448 - acc: 0.9839\n",
      "Epoch 00107: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0448 - acc: 0.9839 - val_loss: 0.0705 - val_acc: 0.9797\n",
      "Epoch 108/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0461 - acc: 0.9833\n",
      "Epoch 00108: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0460 - acc: 0.9833 - val_loss: 0.0712 - val_acc: 0.9778\n",
      "Epoch 109/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0444 - acc: 0.9837\n",
      "Epoch 00109: val_loss improved from 0.06910 to 0.06784, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0443 - acc: 0.9838 - val_loss: 0.0678 - val_acc: 0.9797\n",
      "Epoch 110/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0404 - acc: 0.9852\n",
      "Epoch 00110: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0404 - acc: 0.9852 - val_loss: 0.0725 - val_acc: 0.9787\n",
      "Epoch 111/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9856\n",
      "Epoch 00111: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0410 - acc: 0.9855 - val_loss: 0.0720 - val_acc: 0.9781\n",
      "Epoch 112/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0424 - acc: 0.9848\n",
      "Epoch 00112: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0423 - acc: 0.9848 - val_loss: 0.0700 - val_acc: 0.9787\n",
      "Epoch 113/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0409 - acc: 0.9850\n",
      "Epoch 00113: val_loss improved from 0.06784 to 0.06664, saving model to best.hdf5\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0410 - acc: 0.9850 - val_loss: 0.0666 - val_acc: 0.9790\n",
      "Epoch 114/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0413 - acc: 0.9855\n",
      "Epoch 00114: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0412 - acc: 0.9855 - val_loss: 0.0702 - val_acc: 0.9790\n",
      "Epoch 115/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9858\n",
      "Epoch 00115: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0411 - acc: 0.9858 - val_loss: 0.0712 - val_acc: 0.9797\n",
      "Epoch 116/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0410 - acc: 0.9857\n",
      "Epoch 00116: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0409 - acc: 0.9856 - val_loss: 0.0670 - val_acc: 0.9815\n",
      "Epoch 117/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0393 - acc: 0.9859\n",
      "Epoch 00117: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0393 - acc: 0.9859 - val_loss: 0.0697 - val_acc: 0.9781\n",
      "Epoch 118/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0411 - acc: 0.9849\n",
      "Epoch 00118: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0411 - acc: 0.9848 - val_loss: 0.0734 - val_acc: 0.9784\n",
      "Epoch 119/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0397 - acc: 0.9854\n",
      "Epoch 00119: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0398 - acc: 0.9854 - val_loss: 0.0702 - val_acc: 0.9790\n",
      "Epoch 120/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0391 - acc: 0.9863\n",
      "Epoch 00120: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0390 - acc: 0.9864 - val_loss: 0.0720 - val_acc: 0.9794\n",
      "Epoch 121/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0387 - acc: 0.9857\n",
      "Epoch 00121: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0387 - acc: 0.9857 - val_loss: 0.0684 - val_acc: 0.9794\n",
      "Epoch 122/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0382 - acc: 0.9866\n",
      "Epoch 00122: val_loss did not improve\n",
      "28765/28765 [==============================] - 111s 4ms/step - loss: 0.0383 - acc: 0.9865 - val_loss: 0.0732 - val_acc: 0.9800\n",
      "Epoch 123/5000\n",
      "28672/28765 [============================>.] - ETA: 0s - loss: 0.0395 - acc: 0.9861\n",
      "Epoch 00123: val_loss did not improve\n",
      "28765/28765 [==============================] - 112s 4ms/step - loss: 0.0396 - acc: 0.9861 - val_loss: 0.0738 - val_acc: 0.9803\n",
      "Epoch 00123: early stopping\n"
     ]
    }
   ],
   "source": [
    "#model = genModel( embed = 64, nl = 2, nh = 128 ) #0.07193\n",
    "model = genModel( embed = 64, nl = 3, nh = 64 )\n",
    "\n",
    "model.summary()\n",
    "\n",
    "earlyStoper  = EarlyStopping( patience = 10, verbose = 1 )\n",
    "checkPointer = ModelCheckpoint( filepath = \"best.hdf5\", save_best_only = True, verbose = 1 )\n",
    "\n",
    "hist = model.fit( trainX, trainY,\n",
    "                  validation_data = (valX, valY),\n",
    "                  epochs = 5000,\n",
    "                  #verbose = 0,\n",
    "                  batch_size = 512,\n",
    "                  callbacks = [earlyStoper, checkPointer] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the model on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights( \"best.hdf5\" )\n",
    "pred = model.predict( valX )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valAcc:    0.9790\n",
      "Recall:    0.8541\n",
      "Precision: 0.8578\n",
      "F1:        0.8559\n",
      "MCC:       0.8446\n"
     ]
    }
   ],
   "source": [
    "f1   = f1_score( valY, np.round(pred.flatten()) )\n",
    "acc  = accuracy_score( valY, np.round(pred.flatten()) )\n",
    "rec  = recall_score( valY, np.round(pred.flatten()) )\n",
    "prec = precision_score( valY, np.round(pred.flatten()) )\n",
    "mcc  = matthews_corrcoef( valY, np.round(pred.flatten()) )\n",
    "\n",
    "print( \"valAcc:    {0:1.4f}\\nRecall:    {2:1.4f}\\nPrecision: {3:1.4f}\\nF1:        {1:1.4f}\\nMCC:       {4:1.4f}\".format( acc, f1, rec, prec, mcc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make inferences on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv( \"test_tweets_anuFYb8.csv\" )\n",
    "test[\"label\"] = 0\n",
    "\n",
    "testData, _ = genData( test, c2i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict( testData )\n",
    "test[\"label\"] = np.round( pred.flatten() )\n",
    "test[ [\"id\", \"label\"] ].to_csv( \"submission.csv\", index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the [checker](https://datahack.analyticsvidhya.com/contest/practice-problem-twitter-sentiment-analysis/) this model achieves an $F_1$ on the test set of:\n",
    "\n",
    "$$F_1 = 0.8311688312.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
